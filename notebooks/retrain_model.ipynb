{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81156fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/.venv/lib/python3.11/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/heykalsayid/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mheykalsayid\u001b[0m (\u001b[33mdanielteam\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/heykalsayid/.netrc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from dotenv import load_dotenv\n",
    "from usd_idr_forecasting.trainers import Retrainer\n",
    "from usd_idr_forecasting.configs import ProjectConfig\n",
    "load_dotenv()\n",
    "PROJECT_WORKING_DIR = os.getenv(\"PROJECT_WORKING_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6229622a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProjectConfig(project_name='idrx-forecast', wandb_team_name='danielteam', general={'windowing_size': 42, 'target_size': 1, 'batch_size': [8, 16, 32], 'shuffle_buffer_size': None}, model={'learning_rate': 0.0005, 'momentum': 0.9, 'optimizer': ['adam'], 'epochs': 50, 'rnn': {'units': 128, 'return_sequences': True}, 'conv1d': {'filter': 32, 'kernel_size': 3, 'strides': 1, 'padding': 'causal', 'activation': 'relu', 'name': 'conv1d'}, 'max_pooling_1d': 42, 'dropout': 0.2, 'feed_forward_layer': {'dense_1': {'dense': 10, 'activation': 'relu', 'name': 'dense_1'}, 'output': {'dense': 1, 'name': 'output'}}}, tuner={'batch_size': 32, 'rnn_units': {'min_value': 50, 'max_value': 200, 'step': 30}, 'conv1d': {'filter': {'min_value': 50, 'max_value': 100, 'step': 25}, 'kernel_size': [3, 42]}, 'max_pool1d': {'name': 'max_pool1d'}, 'flattening_layer': ['GlobalAveragePooling1D', 'GlobalMaxPool1D'], 'batch_norm': {'name': 'batch_norm'}, 'dropout': {'name': 'dropout', 'rate': [0.25, 0.2]}, 'dense_units': [50, 42], 'learning_rate': [5e-05, 0.0005], 'optimizers': ['adam', 'nadam']}, dataset={'provider': 'yfinance', 'ticker': 'IDR=X', 'start_date': datetime.date(2002, 1, 1), 'end_date': datetime.date(2025, 9, 1), 'test_fraction': 0.2})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = os.path.join(PROJECT_WORKING_DIR, 'project_configs.yaml')\n",
    "project_config = ProjectConfig.from_yaml(config_path)\n",
    "project_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b544e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_retrainer = Retrainer(\n",
    "\tconfig=project_config, \n",
    "\tbatch_sizes=[16, 32],\n",
    "\tmodel_rank_ids=[0, 1],\n",
    "\trnn_type='lstm',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c9f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "reducer_params = dict(\n",
    "    monitor='val_rmse',\n",
    "    factor=0.05,\n",
    "    patience=5,\n",
    "    verbose=3,\n",
    "    mode='min',\n",
    "    min_delta=5e-7,\n",
    "    cooldown=5,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(**reducer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1946ed3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retraining process_id: 2026120_232746_541172\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/notebooks/wandb/run-20260120_232747-wtkddchr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danielteam/idrx-forecast/runs/wtkddchr' target=\"_blank\">confused-sky-7338</a></strong> to <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danielteam/idrx-forecast/runs/wtkddchr' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/wtkddchr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-sky-7338</strong> at: <a href='https://wandb.ai/danielteam/idrx-forecast/runs/wtkddchr' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/wtkddchr</a><br> View project at: <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_232747-wtkddchr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 best LSTM files:\n",
      "['model-lstm:best-tuned-rank0.keras', 'model-lstm:best-tuned-rank1.keras']\n",
      "5 best gru files:\n",
      "['model-gru:best-tuned-rank0.keras', 'model-gru:best-tuned-rank1.keras']\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/notebooks/wandb/run-20260120_232756-d3g607cx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danielteam/idrx-forecast/runs/d3g607cx' target=\"_blank\">prime-smoke-7339</a></strong> to <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danielteam/idrx-forecast/runs/d3g607cx' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/d3g607cx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   37 of 37 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available preprocessed datasets:\n",
      "\t['train@preprocessed-ds_2025121_172934_626424_batch@8', 'scaler.pkl', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid@preprocessed-ds_2025121_172934_626424_batch@8', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@16', 'valid@preprocessed-ds_2025121_172934_626424_batch@16', 'train@preprocessed-ds_2025121_172934_626424_batch@32', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid@preprocessed-ds_2025121_172934_626424_batch@32', 'train@preprocessed-ds_2025121_172934_626424_batch@16', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@16']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">prime-smoke-7339</strong> at: <a href='https://wandb.ai/danielteam/idrx-forecast/runs/d3g607cx' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/d3g607cx</a><br> View project at: <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_232756-d3g607cx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train@preprocessed-ds_2025121_172934_626424_batch@8', 'scaler.pkl', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid@preprocessed-ds_2025121_172934_626424_batch@8', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@16', 'valid@preprocessed-ds_2025121_172934_626424_batch@16', 'train@preprocessed-ds_2025121_172934_626424_batch@32', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid@preprocessed-ds_2025121_172934_626424_batch@32', 'train@preprocessed-ds_2025121_172934_626424_batch@16', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@16']\n",
      "train index: 11\n",
      "valid index: 7\n",
      "Model path: /Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/notebooks/artifacts/model-lstm--tuned-5best:v12/model-lstm:best-tuned-rank0.keras\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/notebooks/wandb/run-20260120_232804-2026120_232746_541172@lstm@b16@0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b16@0' target=\"_blank\">retrain_best_hp-lstm_@batch16_0</a></strong> to <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b16@0' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b16@0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/.venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 24 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 - 6s - 21ms/step - loss: 0.0038 - mae: 0.0639 - mape: 36638.8945 - mse: 0.0076 - rmse: 0.0871 - val_loss: 0.0751 - val_mae: 0.3856 - val_mape: 45.1647 - val_mse: 0.1503 - val_rmse: 0.3875 - learning_rate: 5.0000e-04\n",
      "Epoch 2/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0128 - mae: 0.1058 - mape: 30847.4629 - mse: 0.0255 - rmse: 0.1598 - val_loss: 0.9487 - val_mae: 1.4243 - val_mape: 160.5876 - val_mse: 2.5143 - val_rmse: 1.5820 - learning_rate: 5.0000e-04\n",
      "Epoch 3/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0135 - mae: 0.1125 - mape: 227217.5469 - mse: 0.0270 - rmse: 0.1646 - val_loss: 2.7896 - val_mae: 3.2921 - val_mape: 384.6422 - val_mse: 11.0472 - val_rmse: 3.3212 - learning_rate: 5.0000e-04\n",
      "Epoch 4/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0152 - mae: 0.1295 - mape: 22381.4707 - mse: 0.0303 - rmse: 0.1744 - val_loss: 5.0756 - val_mae: 5.5744 - val_mape: 660.6653 - val_mse: 31.1427 - val_rmse: 5.5817 - learning_rate: 5.0000e-04\n",
      "Epoch 5/50\n",
      "296/296 - 6s - 19ms/step - loss: 0.0159 - mae: 0.1339 - mape: 56615.4453 - mse: 0.0317 - rmse: 0.1783 - val_loss: 1.8810 - val_mae: 2.3818 - val_mape: 277.5126 - val_mse: 5.8495 - val_rmse: 2.4179 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 2.5000001187436283e-05.\n",
      "296/296 - 6s - 21ms/step - loss: 0.0169 - mae: 0.1397 - mape: 64780.8906 - mse: 0.0338 - rmse: 0.1839 - val_loss: 0.4112 - val_mae: 0.8465 - val_mape: 98.4300 - val_mse: 0.8359 - val_rmse: 0.9131 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0569 - mae: 0.3074 - mape: 102549.0781 - mse: 0.1136 - rmse: 0.3373 - val_loss: 0.7460 - val_mae: 1.2453 - val_mape: 144.0394 - val_mse: 1.6334 - val_rmse: 1.2766 - learning_rate: 2.5000e-05\n",
      "Epoch 8/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0431 - mae: 0.2746 - mape: 76268.1094 - mse: 0.0862 - rmse: 0.2937 - val_loss: 2.0004 - val_mae: 2.5022 - val_mape: 291.6482 - val_mse: 6.4072 - val_rmse: 2.5294 - learning_rate: 2.5000e-05\n",
      "Epoch 9/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0385 - mae: 0.2614 - mape: 69898.8438 - mse: 0.0771 - rmse: 0.2777 - val_loss: 2.7508 - val_mae: 3.2535 - val_mape: 378.5859 - val_mse: 10.8876 - val_rmse: 3.2969 - learning_rate: 2.5000e-05\n",
      "Epoch 10/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0361 - mae: 0.2533 - mape: 66895.7812 - mse: 0.0723 - rmse: 0.2688 - val_loss: 3.4315 - val_mae: 3.9351 - val_mape: 457.0312 - val_mse: 16.0288 - val_rmse: 3.9999 - learning_rate: 2.5000e-05\n",
      "Epoch 11/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0342 - mae: 0.2462 - mape: 65769.9531 - mse: 0.0684 - rmse: 0.2614 - val_loss: 4.0884 - val_mae: 4.5930 - val_mape: 532.4451 - val_mse: 21.9901 - val_rmse: 4.6846 - learning_rate: 2.5000e-05\n",
      "Epoch 12/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0328 - mae: 0.2407 - mape: 64308.0547 - mse: 0.0656 - rmse: 0.2560 - val_loss: 4.7311 - val_mae: 5.2367 - val_mape: 606.3034 - val_mse: 28.7198 - val_rmse: 5.3532 - learning_rate: 2.5000e-05\n",
      "Epoch 13/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0312 - mae: 0.2342 - mape: 61529.1875 - mse: 0.0624 - rmse: 0.2496 - val_loss: 5.3606 - val_mae: 5.8674 - val_mape: 678.2786 - val_mse: 36.2932 - val_rmse: 6.0173 - learning_rate: 2.5000e-05\n",
      "Epoch 14/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0296 - mae: 0.2270 - mape: 60292.3867 - mse: 0.0593 - rmse: 0.2431 - val_loss: 6.1941 - val_mae: 6.7021 - val_mape: 773.9213 - val_mse: 47.5863 - val_rmse: 6.8898 - learning_rate: 2.5000e-05\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.2500000593718142e-06.\n",
      "296/296 - 6s - 19ms/step - loss: 0.0282 - mae: 0.2204 - mape: 56901.5078 - mse: 0.0566 - rmse: 0.2376 - val_loss: 6.9519 - val_mae: 7.4611 - val_mape: 860.9485 - val_mse: 59.1742 - val_rmse: 7.6827 - learning_rate: 2.5000e-05\n",
      "Epoch 16/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0281 - mae: 0.2215 - mape: 53651.9883 - mse: 0.0563 - rmse: 0.2370 - val_loss: 5.5871 - val_mae: 6.0961 - val_mape: 699.9411 - val_mse: 40.5038 - val_rmse: 6.3547 - learning_rate: 1.2500e-06\n",
      "Epoch 17/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0277 - mae: 0.2195 - mape: 51697.7344 - mse: 0.0555 - rmse: 0.2353 - val_loss: 5.3489 - val_mae: 5.8578 - val_mape: 672.0170 - val_mse: 37.5653 - val_rmse: 6.1196 - learning_rate: 1.2500e-06\n",
      "Epoch 18/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0273 - mae: 0.2176 - mape: 50003.0938 - mse: 0.0548 - rmse: 0.2338 - val_loss: 5.1887 - val_mae: 5.6975 - val_mape: 653.2774 - val_mse: 35.6423 - val_rmse: 5.9608 - learning_rate: 1.2500e-06\n",
      "Epoch 19/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0271 - mae: 0.2161 - mape: 48474.8555 - mse: 0.0543 - rmse: 0.2326 - val_loss: 5.0693 - val_mae: 5.5780 - val_mape: 639.3345 - val_mse: 34.2370 - val_rmse: 5.8420 - learning_rate: 1.2500e-06\n",
      "Epoch 20/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0269 - mae: 0.2150 - mape: 47058.7969 - mse: 0.0539 - rmse: 0.2317 - val_loss: 4.9698 - val_mae: 5.4785 - val_mape: 627.7142 - val_mse: 33.0881 - val_rmse: 5.7430 - learning_rate: 1.2500e-06\n",
      "Epoch 21/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0267 - mae: 0.2140 - mape: 45725.8711 - mse: 0.0536 - rmse: 0.2310 - val_loss: 4.8889 - val_mae: 5.3975 - val_mape: 618.2612 - val_mse: 32.1677 - val_rmse: 5.6625 - learning_rate: 1.2500e-06\n",
      "Epoch 22/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0265 - mae: 0.2132 - mape: 44451.8281 - mse: 0.0533 - rmse: 0.2304 - val_loss: 4.8221 - val_mae: 5.3306 - val_mape: 610.4578 - val_mse: 31.4180 - val_rmse: 5.5961 - learning_rate: 1.2500e-06\n",
      "Epoch 23/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0264 - mae: 0.2124 - mape: 43227.3516 - mse: 0.0530 - rmse: 0.2298 - val_loss: 4.7650 - val_mae: 5.2735 - val_mape: 603.7854 - val_mse: 30.7861 - val_rmse: 5.5395 - learning_rate: 1.2500e-06\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "296/296 - 5s - 18ms/step - loss: 0.0263 - mae: 0.2116 - mape: 42048.8398 - mse: 0.0527 - rmse: 0.2292 - val_loss: 4.7134 - val_mae: 5.2219 - val_mape: 597.7551 - val_mse: 30.2244 - val_rmse: 5.4886 - learning_rate: 1.2500e-06\n",
      "Epoch 25/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0261 - mae: 0.2109 - mape: 40948.0117 - mse: 0.0525 - rmse: 0.2286 - val_loss: 4.6652 - val_mae: 5.1737 - val_mape: 592.0869 - val_mse: 29.7086 - val_rmse: 5.4415 - learning_rate: 1.0000e-06\n",
      "Epoch 26/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0260 - mae: 0.2103 - mape: 40063.3867 - mse: 0.0523 - rmse: 0.2282 - val_loss: 4.6291 - val_mae: 5.1376 - val_mape: 587.8550 - val_mse: 29.3262 - val_rmse: 5.4064 - learning_rate: 1.0000e-06\n",
      "Epoch 27/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0259 - mae: 0.2097 - mape: 39199.5352 - mse: 0.0520 - rmse: 0.2277 - val_loss: 4.5895 - val_mae: 5.0980 - val_mape: 583.1906 - val_mse: 28.9129 - val_rmse: 5.3681 - learning_rate: 1.0000e-06\n",
      "Epoch 28/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0258 - mae: 0.2091 - mape: 38386.1836 - mse: 0.0518 - rmse: 0.2272 - val_loss: 4.5422 - val_mae: 5.0507 - val_mape: 577.6145 - val_mse: 28.4282 - val_rmse: 5.3228 - learning_rate: 1.0000e-06\n",
      "Epoch 29/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0257 - mae: 0.2084 - mape: 37626.4336 - mse: 0.0516 - rmse: 0.2267 - val_loss: 4.5062 - val_mae: 5.0146 - val_mape: 573.3562 - val_mse: 28.0630 - val_rmse: 5.2885 - learning_rate: 1.0000e-06\n",
      "Epoch 30/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0256 - mae: 0.2076 - mape: 36911.7852 - mse: 0.0514 - rmse: 0.2262 - val_loss: 4.4773 - val_mae: 4.9857 - val_mape: 569.9353 - val_mse: 27.7746 - val_rmse: 5.2612 - learning_rate: 1.0000e-06\n",
      "Epoch 31/50\n",
      "296/296 - 6s - 19ms/step - loss: 0.0255 - mae: 0.2070 - mape: 36285.6406 - mse: 0.0511 - rmse: 0.2257 - val_loss: 4.4604 - val_mae: 4.9689 - val_mape: 567.9232 - val_mse: 27.6112 - val_rmse: 5.2456 - learning_rate: 1.0000e-06\n",
      "Epoch 32/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0254 - mae: 0.2065 - mape: 35699.0859 - mse: 0.0509 - rmse: 0.2253 - val_loss: 4.4489 - val_mae: 4.9573 - val_mape: 566.5330 - val_mse: 27.5043 - val_rmse: 5.2354 - learning_rate: 1.0000e-06\n",
      "Epoch 33/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0253 - mae: 0.2060 - mape: 35145.9844 - mse: 0.0508 - rmse: 0.2248 - val_loss: 4.4388 - val_mae: 4.9473 - val_mape: 565.3109 - val_mse: 27.4144 - val_rmse: 5.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 34/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0252 - mae: 0.2054 - mape: 34600.2227 - mse: 0.0506 - rmse: 0.2244 - val_loss: 4.4317 - val_mae: 4.9402 - val_mape: 564.4329 - val_mse: 27.3572 - val_rmse: 5.2214 - learning_rate: 1.0000e-06\n",
      "Epoch 35/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0251 - mae: 0.2048 - mape: 34089.8945 - mse: 0.0504 - rmse: 0.2240 - val_loss: 4.4270 - val_mae: 4.9356 - val_mape: 563.8255 - val_mse: 27.3268 - val_rmse: 5.2184 - learning_rate: 1.0000e-06\n",
      "Epoch 36/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0250 - mae: 0.2043 - mape: 33597.8047 - mse: 0.0502 - rmse: 0.2236 - val_loss: 4.4278 - val_mae: 4.9363 - val_mape: 563.8520 - val_mse: 27.3527 - val_rmse: 5.2209 - learning_rate: 1.0000e-06\n",
      "Epoch 37/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0249 - mae: 0.2038 - mape: 33115.7656 - mse: 0.0500 - rmse: 0.2232 - val_loss: 4.4344 - val_mae: 4.9430 - val_mape: 564.5677 - val_mse: 27.4401 - val_rmse: 5.2292 - learning_rate: 1.0000e-06\n",
      "Epoch 38/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0248 - mae: 0.2033 - mape: 32635.9570 - mse: 0.0498 - rmse: 0.2228 - val_loss: 4.4447 - val_mae: 4.9534 - val_mape: 565.7172 - val_mse: 27.5671 - val_rmse: 5.2413 - learning_rate: 1.0000e-06\n",
      "Epoch 39/50\n",
      "296/296 - 5s - 19ms/step - loss: 0.0247 - mae: 0.2028 - mape: 32147.5312 - mse: 0.0497 - rmse: 0.2224 - val_loss: 4.4580 - val_mae: 4.9666 - val_mape: 567.1989 - val_mse: 27.7248 - val_rmse: 5.2562 - learning_rate: 1.0000e-06\n",
      "Epoch 40/50\n",
      "296/296 - 6s - 19ms/step - loss: 0.0246 - mae: 0.2023 - mape: 31667.0820 - mse: 0.0495 - rmse: 0.2220 - val_loss: 4.4697 - val_mae: 4.9784 - val_mape: 568.5028 - val_mse: 27.8703 - val_rmse: 5.2700 - learning_rate: 1.0000e-06\n",
      "Epoch 41/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0245 - mae: 0.2017 - mape: 31186.9941 - mse: 0.0493 - rmse: 0.2216 - val_loss: 4.4866 - val_mae: 4.9953 - val_mape: 570.3982 - val_mse: 28.0684 - val_rmse: 5.2887 - learning_rate: 1.0000e-06\n",
      "Epoch 42/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0245 - mae: 0.2012 - mape: 30704.0879 - mse: 0.0491 - rmse: 0.2212 - val_loss: 4.5052 - val_mae: 5.0140 - val_mape: 572.5081 - val_mse: 28.2869 - val_rmse: 5.3092 - learning_rate: 1.0000e-06\n",
      "Epoch 43/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0244 - mae: 0.2007 - mape: 30220.6152 - mse: 0.0490 - rmse: 0.2208 - val_loss: 4.5238 - val_mae: 5.0326 - val_mape: 574.6004 - val_mse: 28.5062 - val_rmse: 5.3298 - learning_rate: 1.0000e-06\n",
      "Epoch 44/50\n",
      "296/296 - 5s - 18ms/step - loss: 0.0243 - mae: 0.2002 - mape: 29703.2598 - mse: 0.0488 - rmse: 0.2204 - val_loss: 4.5420 - val_mae: 5.0508 - val_mape: 576.6496 - val_mse: 28.7237 - val_rmse: 5.3500 - learning_rate: 1.0000e-06\n",
      "Epoch 45/50\n",
      "296/296 - 5s - 19ms/step - loss: 0.0242 - mae: 0.1997 - mape: 29210.7871 - mse: 0.0486 - rmse: 0.2200 - val_loss: 4.5638 - val_mae: 5.0727 - val_mape: 579.1279 - val_mse: 28.9799 - val_rmse: 5.3738 - learning_rate: 1.0000e-06\n",
      "Epoch 46/50\n",
      "296/296 - 5s - 19ms/step - loss: 0.0241 - mae: 0.1992 - mape: 28734.9121 - mse: 0.0484 - rmse: 0.2195 - val_loss: 4.5840 - val_mae: 5.0930 - val_mape: 581.4069 - val_mse: 29.2217 - val_rmse: 5.3962 - learning_rate: 1.0000e-06\n",
      "Epoch 47/50\n",
      "296/296 - 5s - 19ms/step - loss: 0.0240 - mae: 0.1986 - mape: 28260.0059 - mse: 0.0482 - rmse: 0.2191 - val_loss: 4.6098 - val_mae: 5.1188 - val_mape: 584.3420 - val_mse: 29.5219 - val_rmse: 5.4238 - learning_rate: 1.0000e-06\n",
      "Epoch 48/50\n",
      "296/296 - 6s - 19ms/step - loss: 0.0239 - mae: 0.1981 - mape: 27792.5508 - mse: 0.0481 - rmse: 0.2187 - val_loss: 4.6331 - val_mae: 5.1421 - val_mape: 586.9907 - val_mse: 29.7993 - val_rmse: 5.4493 - learning_rate: 1.0000e-06\n",
      "Epoch 49/50\n",
      "296/296 - 5s - 19ms/step - loss: 0.0238 - mae: 0.1976 - mape: 27333.2852 - mse: 0.0479 - rmse: 0.2183 - val_loss: 4.6563 - val_mae: 5.1654 - val_mape: 589.6196 - val_mse: 30.0779 - val_rmse: 5.4747 - learning_rate: 1.0000e-06\n",
      "Epoch 50/50\n",
      "296/296 - 5s - 19ms/step - loss: 0.0237 - mae: 0.1971 - mape: 26894.4023 - mse: 0.0477 - rmse: 0.2179 - val_loss: 4.6774 - val_mae: 5.1866 - val_mape: 591.9968 - val_mse: 30.3366 - val_rmse: 5.4981 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>█████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>▁▂▂▃▃█▆▆▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>epoch/mae</td><td>▁▂▂▃▃█▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>epoch/mape</td><td>▁▁█▁▂▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mse</td><td>▁▂▂▃▃█▆▆▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>epoch/rmse</td><td>▁▃▃▃▄█▇▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>epoch/val_loss</td><td>▁▂▄▆▃▂▃▄▄▅▇█▇▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆</td></tr><tr><td>epoch/val_mae</td><td>▁▂▄▆▃▂▃▄▅▅▆▇█▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>epoch/val_mape</td><td>▁▂▄▃▁▃▄▅▅▆▇█▇▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.0</td></tr><tr><td>epoch/loss</td><td>0.02373</td></tr><tr><td>epoch/mae</td><td>0.19706</td></tr><tr><td>epoch/mape</td><td>26894.40234</td></tr><tr><td>epoch/mse</td><td>0.0477</td></tr><tr><td>epoch/rmse</td><td>0.21787</td></tr><tr><td>epoch/val_loss</td><td>4.6774</td></tr><tr><td>epoch/val_mae</td><td>5.18655</td></tr><tr><td>epoch/val_mape</td><td>591.99683</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">retrain_best_hp-lstm_@batch16_0</strong> at: <a href='https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b16@0' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b16@0</a><br> View project at: <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_232804-2026120_232746_541172@lstm@b16@0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/notebooks/wandb/run-20260120_233241-m5xsorsx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danielteam/idrx-forecast/runs/m5xsorsx' target=\"_blank\">happy-planet-7341</a></strong> to <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danielteam/idrx-forecast/runs/m5xsorsx' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/m5xsorsx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   37 of 37 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available preprocessed datasets:\n",
      "\t['train@preprocessed-ds_2025121_172934_626424_batch@8', 'scaler.pkl', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid@preprocessed-ds_2025121_172934_626424_batch@8', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@16', 'valid@preprocessed-ds_2025121_172934_626424_batch@16', 'train@preprocessed-ds_2025121_172934_626424_batch@32', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid@preprocessed-ds_2025121_172934_626424_batch@32', 'train@preprocessed-ds_2025121_172934_626424_batch@16', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@16']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-planet-7341</strong> at: <a href='https://wandb.ai/danielteam/idrx-forecast/runs/m5xsorsx' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/m5xsorsx</a><br> View project at: <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_233241-m5xsorsx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train@preprocessed-ds_2025121_172934_626424_batch@8', 'scaler.pkl', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid@preprocessed-ds_2025121_172934_626424_batch@8', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@16', 'valid@preprocessed-ds_2025121_172934_626424_batch@16', 'train@preprocessed-ds_2025121_172934_626424_batch@32', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid@preprocessed-ds_2025121_172934_626424_batch@32', 'train@preprocessed-ds_2025121_172934_626424_batch@16', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@16']\n",
      "train index: 11\n",
      "valid index: 7\n",
      "Model path: /Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/notebooks/artifacts/model-lstm--tuned-5best:v12/model-lstm:best-tuned-rank1.keras\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/notebooks/wandb/run-20260120_233249-2026120_232746_541172@lstm@b16@1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b16@1' target=\"_blank\">retrain_best_hp-lstm_@batch16_1</a></strong> to <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b16@1' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b16@1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/.venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'nadam', because it has 25 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "296/296 - 9s - 30ms/step - loss: 0.0232 - mae: 0.1549 - mape: 12130.3408 - mse: 0.0470 - rmse: 0.2162 - val_loss: 0.1086 - val_mae: 0.4338 - val_mape: 53.2291 - val_mse: 0.2167 - val_rmse: 0.4662 - learning_rate: 5.0000e-05\n",
      "Epoch 2/50\n",
      "296/296 - 7s - 25ms/step - loss: 0.0256 - mae: 0.1897 - mape: 92702.5156 - mse: 0.0515 - rmse: 0.2265 - val_loss: 0.8095 - val_mae: 1.2416 - val_mape: 137.5236 - val_mse: 2.3027 - val_rmse: 1.5121 - learning_rate: 5.0000e-05\n",
      "Epoch 3/50\n",
      "296/296 - 7s - 25ms/step - loss: 0.0246 - mae: 0.1870 - mape: 110021.1484 - mse: 0.0494 - rmse: 0.2219 - val_loss: 7.6055 - val_mae: 8.1191 - val_mape: 928.3785 - val_mse: 73.3652 - val_rmse: 8.5508 - learning_rate: 5.0000e-05\n",
      "Epoch 4/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0205 - mae: 0.1651 - mape: 86860.1641 - mse: 0.0413 - rmse: 0.2027 - val_loss: 3.0037 - val_mae: 3.4942 - val_mape: 387.0382 - val_mse: 17.1415 - val_rmse: 4.1287 - learning_rate: 5.0000e-05\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "296/296 - 7s - 25ms/step - loss: 0.0179 - mae: 0.1536 - mape: 12796.5518 - mse: 0.0360 - rmse: 0.1890 - val_loss: 5.0598 - val_mae: 5.5713 - val_mape: 631.6672 - val_mse: 36.3042 - val_rmse: 6.0131 - learning_rate: 5.0000e-05\n",
      "Epoch 6/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0275 - mae: 0.2087 - mape: 23683.4199 - mse: 0.0552 - rmse: 0.2346 - val_loss: 6.9324 - val_mae: 7.4416 - val_mape: 858.5715 - val_mse: 58.7701 - val_rmse: 7.6565 - learning_rate: 2.5000e-06\n",
      "Epoch 7/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0211 - mae: 0.1807 - mape: 5563.4639 - mse: 0.0425 - rmse: 0.2056 - val_loss: 6.9059 - val_mae: 7.4148 - val_mape: 856.0994 - val_mse: 58.1667 - val_rmse: 7.6173 - learning_rate: 2.5000e-06\n",
      "Epoch 8/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0195 - mae: 0.1713 - mape: 1111.3909 - mse: 0.0393 - rmse: 0.1975 - val_loss: 6.6506 - val_mae: 7.1593 - val_mape: 826.2126 - val_mse: 54.3448 - val_rmse: 7.3626 - learning_rate: 2.5000e-06\n",
      "Epoch 9/50\n",
      "296/296 - 8s - 28ms/step - loss: 0.0186 - mae: 0.1652 - mape: 3254.0693 - mse: 0.0374 - rmse: 0.1927 - val_loss: 6.5720 - val_mae: 7.0808 - val_mape: 816.8003 - val_mse: 53.2659 - val_rmse: 7.2890 - learning_rate: 2.5000e-06\n",
      "Epoch 10/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0180 - mae: 0.1615 - mape: 5842.8750 - mse: 0.0363 - rmse: 0.1897 - val_loss: 6.5403 - val_mae: 7.0492 - val_mape: 812.8041 - val_mse: 52.9031 - val_rmse: 7.2640 - learning_rate: 2.5000e-06\n",
      "Epoch 11/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0176 - mae: 0.1586 - mape: 8927.8555 - mse: 0.0354 - rmse: 0.1874 - val_loss: 6.5674 - val_mae: 7.0765 - val_mape: 815.6135 - val_mse: 53.4206 - val_rmse: 7.2993 - learning_rate: 2.5000e-06\n",
      "Epoch 12/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0171 - mae: 0.1558 - mape: 9083.6953 - mse: 0.0345 - rmse: 0.1851 - val_loss: 6.6398 - val_mae: 7.1492 - val_mape: 823.6140 - val_mse: 54.6454 - val_rmse: 7.3823 - learning_rate: 2.5000e-06\n",
      "Epoch 13/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0168 - mae: 0.1537 - mape: 8826.7822 - mse: 0.0340 - rmse: 0.1835 - val_loss: 6.7327 - val_mae: 7.2424 - val_mape: 834.0280 - val_mse: 56.1848 - val_rmse: 7.4855 - learning_rate: 2.5000e-06\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "296/296 - 8s - 26ms/step - loss: 0.0166 - mae: 0.1522 - mape: 10236.0166 - mse: 0.0335 - rmse: 0.1822 - val_loss: 6.8278 - val_mae: 7.3377 - val_mape: 844.7008 - val_mse: 57.7766 - val_rmse: 7.5906 - learning_rate: 2.5000e-06\n",
      "Epoch 15/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0164 - mae: 0.1513 - mape: 9929.4268 - mse: 0.0331 - rmse: 0.1811 - val_loss: 5.6900 - val_mae: 6.1995 - val_mape: 710.9780 - val_mse: 42.0503 - val_rmse: 6.4745 - learning_rate: 1.0000e-06\n",
      "Epoch 16/50\n",
      "296/296 - 8s - 27ms/step - loss: 0.0163 - mae: 0.1504 - mape: 9941.6650 - mse: 0.0328 - rmse: 0.1803 - val_loss: 5.6077 - val_mae: 6.1171 - val_mape: 701.4228 - val_mse: 40.9742 - val_rmse: 6.3911 - learning_rate: 1.0000e-06\n",
      "Epoch 17/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0162 - mae: 0.1498 - mape: 9511.4814 - mse: 0.0326 - rmse: 0.1797 - val_loss: 5.6033 - val_mae: 6.1127 - val_mape: 700.8739 - val_mse: 40.9304 - val_rmse: 6.3877 - learning_rate: 1.0000e-06\n",
      "Epoch 18/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0161 - mae: 0.1492 - mape: 9805.1396 - mse: 0.0324 - rmse: 0.1792 - val_loss: 5.6176 - val_mae: 6.1270 - val_mape: 702.4423 - val_mse: 41.1449 - val_rmse: 6.4044 - learning_rate: 1.0000e-06\n",
      "Epoch 19/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0160 - mae: 0.1486 - mape: 9484.7188 - mse: 0.0322 - rmse: 0.1787 - val_loss: 5.6447 - val_mae: 6.1542 - val_mape: 705.4901 - val_mse: 41.5347 - val_rmse: 6.4346 - learning_rate: 1.0000e-06\n",
      "Epoch 20/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0159 - mae: 0.1481 - mape: 9371.9834 - mse: 0.0321 - rmse: 0.1782 - val_loss: 5.6838 - val_mae: 6.1934 - val_mape: 709.9202 - val_mse: 42.0865 - val_rmse: 6.4772 - learning_rate: 1.0000e-06\n",
      "Epoch 21/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0158 - mae: 0.1477 - mape: 9670.4531 - mse: 0.0319 - rmse: 0.1778 - val_loss: 5.7208 - val_mae: 6.2305 - val_mape: 714.0960 - val_mse: 42.6165 - val_rmse: 6.5178 - learning_rate: 1.0000e-06\n",
      "Epoch 22/50\n",
      "296/296 - 8s - 25ms/step - loss: 0.0157 - mae: 0.1472 - mape: 9976.2725 - mse: 0.0318 - rmse: 0.1774 - val_loss: 5.7546 - val_mae: 6.2644 - val_mape: 717.9095 - val_mse: 43.1077 - val_rmse: 6.5552 - learning_rate: 1.0000e-06\n",
      "Epoch 23/50\n",
      "296/296 - 8s - 25ms/step - loss: 0.0157 - mae: 0.1468 - mape: 10234.8779 - mse: 0.0317 - rmse: 0.1771 - val_loss: 5.7919 - val_mae: 6.3018 - val_mape: 722.1196 - val_mse: 43.6482 - val_rmse: 6.5962 - learning_rate: 1.0000e-06\n",
      "Epoch 24/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0156 - mae: 0.1464 - mape: 10440.9785 - mse: 0.0315 - rmse: 0.1767 - val_loss: 5.8315 - val_mae: 6.3415 - val_mape: 726.6049 - val_mse: 44.2249 - val_rmse: 6.6396 - learning_rate: 1.0000e-06\n",
      "Epoch 25/50\n",
      "296/296 - 8s - 25ms/step - loss: 0.0156 - mae: 0.1460 - mape: 10921.0791 - mse: 0.0314 - rmse: 0.1764 - val_loss: 5.8670 - val_mae: 6.3770 - val_mape: 730.5983 - val_mse: 44.7480 - val_rmse: 6.6787 - learning_rate: 1.0000e-06\n",
      "Epoch 26/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0155 - mae: 0.1456 - mape: 11322.7939 - mse: 0.0313 - rmse: 0.1760 - val_loss: 5.9023 - val_mae: 6.4125 - val_mape: 734.5854 - val_mse: 45.2734 - val_rmse: 6.7177 - learning_rate: 1.0000e-06\n",
      "Epoch 27/50\n",
      "296/296 - 8s - 25ms/step - loss: 0.0154 - mae: 0.1452 - mape: 11675.9502 - mse: 0.0312 - rmse: 0.1757 - val_loss: 5.9436 - val_mae: 6.4539 - val_mape: 739.2634 - val_mse: 45.8811 - val_rmse: 6.7626 - learning_rate: 1.0000e-06\n",
      "Epoch 28/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0154 - mae: 0.1448 - mape: 12043.7217 - mse: 0.0311 - rmse: 0.1753 - val_loss: 5.9787 - val_mae: 6.4890 - val_mape: 743.2177 - val_mse: 46.4078 - val_rmse: 6.8013 - learning_rate: 1.0000e-06\n",
      "Epoch 29/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0153 - mae: 0.1445 - mape: 12245.5508 - mse: 0.0309 - rmse: 0.1750 - val_loss: 6.0168 - val_mae: 6.5272 - val_mape: 747.5250 - val_mse: 46.9818 - val_rmse: 6.8432 - learning_rate: 1.0000e-06\n",
      "Epoch 30/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0153 - mae: 0.1441 - mape: 12535.9688 - mse: 0.0308 - rmse: 0.1747 - val_loss: 6.0558 - val_mae: 6.5664 - val_mape: 751.9378 - val_mse: 47.5721 - val_rmse: 6.8860 - learning_rate: 1.0000e-06\n",
      "Epoch 31/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0152 - mae: 0.1437 - mape: 13070.1592 - mse: 0.0307 - rmse: 0.1743 - val_loss: 6.0939 - val_mae: 6.6046 - val_mape: 756.2469 - val_mse: 48.1525 - val_rmse: 6.9279 - learning_rate: 1.0000e-06\n",
      "Epoch 32/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0151 - mae: 0.1433 - mape: 12940.6416 - mse: 0.0306 - rmse: 0.1740 - val_loss: 6.1325 - val_mae: 6.6432 - val_mape: 760.6086 - val_mse: 48.7428 - val_rmse: 6.9702 - learning_rate: 1.0000e-06\n",
      "Epoch 33/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0151 - mae: 0.1430 - mape: 13121.5547 - mse: 0.0305 - rmse: 0.1736 - val_loss: 6.1589 - val_mae: 6.6697 - val_mape: 763.5473 - val_mse: 49.1670 - val_rmse: 7.0004 - learning_rate: 1.0000e-06\n",
      "Epoch 34/50\n",
      "296/296 - 8s - 25ms/step - loss: 0.0150 - mae: 0.1426 - mape: 13739.8105 - mse: 0.0304 - rmse: 0.1733 - val_loss: 6.2022 - val_mae: 6.7131 - val_mape: 768.4535 - val_mse: 49.8349 - val_rmse: 7.0478 - learning_rate: 1.0000e-06\n",
      "Epoch 35/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0150 - mae: 0.1423 - mape: 13734.4717 - mse: 0.0303 - rmse: 0.1730 - val_loss: 6.2275 - val_mae: 6.7385 - val_mape: 771.2152 - val_mse: 50.2683 - val_rmse: 7.0783 - learning_rate: 1.0000e-06\n",
      "Epoch 36/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0149 - mae: 0.1419 - mape: 14456.3154 - mse: 0.0302 - rmse: 0.1727 - val_loss: 6.2743 - val_mae: 6.7854 - val_mape: 776.5114 - val_mse: 50.9987 - val_rmse: 7.1295 - learning_rate: 1.0000e-06\n",
      "Epoch 37/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0149 - mae: 0.1416 - mape: 14531.6504 - mse: 0.0301 - rmse: 0.1724 - val_loss: 6.2946 - val_mae: 6.8058 - val_mape: 778.6750 - val_mse: 51.3725 - val_rmse: 7.1555 - learning_rate: 1.0000e-06\n",
      "Epoch 38/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0148 - mae: 0.1413 - mape: 15003.8770 - mse: 0.0300 - rmse: 0.1721 - val_loss: 6.3349 - val_mae: 6.8463 - val_mape: 783.3085 - val_mse: 51.9818 - val_rmse: 7.1978 - learning_rate: 1.0000e-06\n",
      "Epoch 39/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0148 - mae: 0.1410 - mape: 15275.2842 - mse: 0.0299 - rmse: 0.1719 - val_loss: 6.3617 - val_mae: 6.8731 - val_mape: 786.3308 - val_mse: 52.4076 - val_rmse: 7.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 40/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0147 - mae: 0.1407 - mape: 15718.2363 - mse: 0.0298 - rmse: 0.1716 - val_loss: 6.3832 - val_mae: 6.8947 - val_mape: 788.6816 - val_mse: 52.7834 - val_rmse: 7.2530 - learning_rate: 1.0000e-06\n",
      "Epoch 41/50\n",
      "296/296 - 8s - 25ms/step - loss: 0.0147 - mae: 0.1404 - mape: 15795.7686 - mse: 0.0297 - rmse: 0.1713 - val_loss: 6.4100 - val_mae: 6.9215 - val_mape: 791.7029 - val_mse: 53.2150 - val_rmse: 7.2826 - learning_rate: 1.0000e-06\n",
      "Epoch 42/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0146 - mae: 0.1401 - mape: 16397.8398 - mse: 0.0296 - rmse: 0.1711 - val_loss: 6.4301 - val_mae: 6.9417 - val_mape: 793.9185 - val_mse: 53.5652 - val_rmse: 7.3064 - learning_rate: 1.0000e-06\n",
      "Epoch 43/50\n",
      "296/296 - 8s - 26ms/step - loss: 0.0146 - mae: 0.1398 - mape: 16309.4883 - mse: 0.0295 - rmse: 0.1708 - val_loss: 6.4585 - val_mae: 6.9702 - val_mape: 797.1193 - val_mse: 54.0288 - val_rmse: 7.3380 - learning_rate: 1.0000e-06\n",
      "Epoch 44/50\n",
      "296/296 - 9s - 30ms/step - loss: 0.0145 - mae: 0.1395 - mape: 16768.2617 - mse: 0.0294 - rmse: 0.1705 - val_loss: 6.4895 - val_mae: 7.0013 - val_mape: 800.5901 - val_mse: 54.5434 - val_rmse: 7.3728 - learning_rate: 1.0000e-06\n",
      "Epoch 45/50\n",
      "296/296 - 8s - 27ms/step - loss: 0.0145 - mae: 0.1391 - mape: 16575.3516 - mse: 0.0293 - rmse: 0.1702 - val_loss: 6.5109 - val_mae: 7.0228 - val_mape: 802.9502 - val_mse: 54.9185 - val_rmse: 7.3980 - learning_rate: 1.0000e-06\n",
      "Epoch 46/50\n",
      "296/296 - 8s - 28ms/step - loss: 0.0144 - mae: 0.1388 - mape: 17321.3047 - mse: 0.0292 - rmse: 0.1699 - val_loss: 6.5349 - val_mae: 7.0469 - val_mape: 805.6295 - val_mse: 55.3255 - val_rmse: 7.4254 - learning_rate: 1.0000e-06\n",
      "Epoch 47/50\n",
      "296/296 - 8s - 27ms/step - loss: 0.0144 - mae: 0.1385 - mape: 16916.8965 - mse: 0.0291 - rmse: 0.1696 - val_loss: 6.5648 - val_mae: 7.0768 - val_mape: 808.9763 - val_mse: 55.8275 - val_rmse: 7.4589 - learning_rate: 1.0000e-06\n",
      "Epoch 48/50\n",
      "296/296 - 8s - 27ms/step - loss: 0.0143 - mae: 0.1382 - mape: 17200.5195 - mse: 0.0290 - rmse: 0.1692 - val_loss: 6.5852 - val_mae: 7.0973 - val_mape: 811.1754 - val_mse: 56.2128 - val_rmse: 7.4846 - learning_rate: 1.0000e-06\n",
      "Epoch 49/50\n",
      "296/296 - 8s - 27ms/step - loss: 0.0143 - mae: 0.1378 - mape: 16870.4590 - mse: 0.0289 - rmse: 0.1689 - val_loss: 6.6153 - val_mae: 7.1276 - val_mape: 814.5286 - val_mse: 56.7333 - val_rmse: 7.5191 - learning_rate: 1.0000e-06\n",
      "Epoch 50/50\n",
      "296/296 - 8s - 27ms/step - loss: 0.0142 - mae: 0.1375 - mape: 17573.4551 - mse: 0.0288 - rmse: 0.1686 - val_loss: 6.6542 - val_mae: 7.1665 - val_mape: 818.9468 - val_mse: 57.3674 - val_rmse: 7.5610 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>▇█▇▅▃▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mae</td><td>▆▆▄▃█▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mape</td><td>▂▇█▇▂▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>epoch/mse</td><td>▇█▇▅▃▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/rmse</td><td>▆▇▇▅█▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>▁▂█▄▆▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>epoch/val_mae</td><td>▁▂█▄▆▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>epoch/val_mape</td><td>▁▂█▄▆▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.0</td></tr><tr><td>epoch/loss</td><td>0.01421</td></tr><tr><td>epoch/mae</td><td>0.13752</td></tr><tr><td>epoch/mape</td><td>17573.45508</td></tr><tr><td>epoch/mse</td><td>0.02877</td></tr><tr><td>epoch/rmse</td><td>0.16861</td></tr><tr><td>epoch/val_loss</td><td>6.65418</td></tr><tr><td>epoch/val_mae</td><td>7.16648</td></tr><tr><td>epoch/val_mape</td><td>818.94678</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">retrain_best_hp-lstm_@batch16_1</strong> at: <a href='https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b16@1' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b16@1</a><br> View project at: <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_233249-2026120_232746_541172@lstm@b16@1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/notebooks/wandb/run-20260120_233918-3kyt3ay2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danielteam/idrx-forecast/runs/3kyt3ay2' target=\"_blank\">magic-totem-7343</a></strong> to <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danielteam/idrx-forecast/runs/3kyt3ay2' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/3kyt3ay2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   37 of 37 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available preprocessed datasets:\n",
      "\t['train@preprocessed-ds_2025121_172934_626424_batch@8', 'scaler.pkl', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid@preprocessed-ds_2025121_172934_626424_batch@8', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@16', 'valid@preprocessed-ds_2025121_172934_626424_batch@16', 'train@preprocessed-ds_2025121_172934_626424_batch@32', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid@preprocessed-ds_2025121_172934_626424_batch@32', 'train@preprocessed-ds_2025121_172934_626424_batch@16', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@16']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">magic-totem-7343</strong> at: <a href='https://wandb.ai/danielteam/idrx-forecast/runs/3kyt3ay2' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/3kyt3ay2</a><br> View project at: <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_233918-3kyt3ay2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train@preprocessed-ds_2025121_172934_626424_batch@8', 'scaler.pkl', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid@preprocessed-ds_2025121_172934_626424_batch@8', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@16', 'valid@preprocessed-ds_2025121_172934_626424_batch@16', 'train@preprocessed-ds_2025121_172934_626424_batch@32', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid@preprocessed-ds_2025121_172934_626424_batch@32', 'train@preprocessed-ds_2025121_172934_626424_batch@16', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@16']\n",
      "train index: 8\n",
      "valid index: 10\n",
      "Model path: /Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/notebooks/artifacts/model-lstm--tuned-5best:v12/model-lstm:best-tuned-rank0.keras\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/notebooks/wandb/run-20260120_233925-2026120_232746_541172@lstm@b32@0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b32@0' target=\"_blank\">retrain_best_hp-lstm_@batch32_0</a></strong> to <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b32@0' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b32@0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/.venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 24 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 - 6s - 37ms/step - loss: 0.0099 - mae: 0.1032 - mape: 64838.0117 - mse: 0.0198 - rmse: 0.1409 - val_loss: 0.3752 - val_mae: 0.8553 - val_mape: 99.4265 - val_mse: 0.7527 - val_rmse: 0.8668 - learning_rate: 5.0000e-04\n",
      "Epoch 2/50\n",
      "148/148 - 5s - 33ms/step - loss: 0.0236 - mae: 0.1719 - mape: 17268.1953 - mse: 0.0471 - rmse: 0.2172 - val_loss: 2.4981 - val_mae: 2.9990 - val_mape: 352.7455 - val_mse: 9.0353 - val_rmse: 3.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 3/50\n",
      "148/148 - 5s - 32ms/step - loss: 0.0250 - mae: 0.1812 - mape: 52616.9531 - mse: 0.0500 - rmse: 0.2238 - val_loss: 2.6108 - val_mae: 3.1128 - val_mape: 363.4758 - val_mse: 9.8864 - val_rmse: 3.1422 - learning_rate: 5.0000e-04\n",
      "Epoch 4/50\n",
      "148/148 - 5s - 31ms/step - loss: 0.0271 - mae: 0.1791 - mape: 130817.6484 - mse: 0.0541 - rmse: 0.2328 - val_loss: 8.8195 - val_mae: 9.3230 - val_mape: 1094.9520 - val_mse: 87.5134 - val_rmse: 9.3513 - learning_rate: 5.0000e-04\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.5000001187436283e-05.\n",
      "148/148 - 5s - 31ms/step - loss: 0.0235 - mae: 0.1674 - mape: 85825.3047 - mse: 0.0469 - rmse: 0.2166 - val_loss: 28.9444 - val_mae: 29.4505 - val_mape: 3470.1846 - val_mse: 869.0942 - val_rmse: 29.4742 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "148/148 - 5s - 33ms/step - loss: 0.0591 - mae: 0.3072 - mape: 195862.5469 - mse: 0.1181 - rmse: 0.3438 - val_loss: 4.1699 - val_mae: 4.6712 - val_mape: 548.9920 - val_mse: 21.9393 - val_rmse: 4.6826 - learning_rate: 2.5000e-05\n",
      "Epoch 7/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0394 - mae: 0.2622 - mape: 104881.5078 - mse: 0.0789 - rmse: 0.2809 - val_loss: 1.1074 - val_mae: 1.6094 - val_mape: 185.5783 - val_mse: 2.7780 - val_rmse: 1.6646 - learning_rate: 2.5000e-05\n",
      "Epoch 8/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0343 - mae: 0.2447 - mape: 74540.2734 - mse: 0.0686 - rmse: 0.2619 - val_loss: 0.5127 - val_mae: 0.9818 - val_mape: 112.3208 - val_mse: 1.0884 - val_rmse: 1.0416 - learning_rate: 2.5000e-05\n",
      "Epoch 9/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0319 - mae: 0.2349 - mape: 61859.4727 - mse: 0.0640 - rmse: 0.2528 - val_loss: 0.5349 - val_mae: 1.0129 - val_mape: 116.2813 - val_mse: 1.1327 - val_rmse: 1.0628 - learning_rate: 2.5000e-05\n",
      "Epoch 10/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0305 - mae: 0.2283 - mape: 55750.4883 - mse: 0.0611 - rmse: 0.2470 - val_loss: 0.6217 - val_mae: 1.1089 - val_mape: 127.4411 - val_mse: 1.3478 - val_rmse: 1.1593 - learning_rate: 2.5000e-05\n",
      "Epoch 11/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0292 - mae: 0.2224 - mape: 51185.2148 - mse: 0.0586 - rmse: 0.2418 - val_loss: 0.7227 - val_mae: 1.2150 - val_mape: 139.4676 - val_mse: 1.6264 - val_rmse: 1.2734 - learning_rate: 2.5000e-05\n",
      "Epoch 12/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0279 - mae: 0.2163 - mape: 47204.7812 - mse: 0.0560 - rmse: 0.2364 - val_loss: 0.8420 - val_mae: 1.3371 - val_mape: 153.0523 - val_mse: 1.9969 - val_rmse: 1.4108 - learning_rate: 2.5000e-05\n",
      "Epoch 13/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0265 - mae: 0.2092 - mape: 42479.2031 - mse: 0.0532 - rmse: 0.2303 - val_loss: 0.9763 - val_mae: 1.4732 - val_mape: 168.0856 - val_mse: 2.4702 - val_rmse: 1.5689 - learning_rate: 2.5000e-05\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.2500000593718142e-06.\n",
      "148/148 - 5s - 34ms/step - loss: 0.0249 - mae: 0.2010 - mape: 36825.0625 - mse: 0.0500 - rmse: 0.2232 - val_loss: 1.1643 - val_mae: 1.6639 - val_mape: 189.3090 - val_mse: 3.2058 - val_rmse: 1.7871 - learning_rate: 2.5000e-05\n",
      "Epoch 15/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0239 - mae: 0.1994 - mape: 31325.4453 - mse: 0.0480 - rmse: 0.2187 - val_loss: 1.3603 - val_mae: 1.8634 - val_mape: 212.9325 - val_mse: 3.9014 - val_rmse: 1.9719 - learning_rate: 1.2500e-06\n",
      "Epoch 16/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0237 - mae: 0.1979 - mape: 27783.7910 - mse: 0.0475 - rmse: 0.2175 - val_loss: 1.3768 - val_mae: 1.8799 - val_mape: 214.9697 - val_mse: 3.9536 - val_rmse: 1.9851 - learning_rate: 1.2500e-06\n",
      "Epoch 17/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0234 - mae: 0.1965 - mape: 24542.2617 - mse: 0.0470 - rmse: 0.2164 - val_loss: 1.3494 - val_mae: 1.8525 - val_mape: 211.7722 - val_mse: 3.8461 - val_rmse: 1.9579 - learning_rate: 1.2500e-06\n",
      "Epoch 18/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0232 - mae: 0.1951 - mape: 21610.1309 - mse: 0.0466 - rmse: 0.2155 - val_loss: 1.3147 - val_mae: 1.8177 - val_mape: 207.6821 - val_mse: 3.7151 - val_rmse: 1.9242 - learning_rate: 1.2500e-06\n",
      "Epoch 19/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0230 - mae: 0.1939 - mape: 18879.7480 - mse: 0.0462 - rmse: 0.2146 - val_loss: 1.2811 - val_mae: 1.7839 - val_mape: 203.7005 - val_mse: 3.5912 - val_rmse: 1.8918 - learning_rate: 1.2500e-06\n",
      "Epoch 20/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0229 - mae: 0.1927 - mape: 16184.2148 - mse: 0.0459 - rmse: 0.2138 - val_loss: 1.2497 - val_mae: 1.7522 - val_mape: 199.9704 - val_mse: 3.4780 - val_rmse: 1.8617 - learning_rate: 1.2500e-06\n",
      "Epoch 21/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0227 - mae: 0.1915 - mape: 13722.2529 - mse: 0.0456 - rmse: 0.2131 - val_loss: 1.2224 - val_mae: 1.7245 - val_mape: 196.6892 - val_mse: 3.3809 - val_rmse: 1.8355 - learning_rate: 1.2500e-06\n",
      "Epoch 22/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0226 - mae: 0.1905 - mape: 11456.0527 - mse: 0.0453 - rmse: 0.2124 - val_loss: 1.1974 - val_mae: 1.6989 - val_mape: 193.6699 - val_mse: 3.2937 - val_rmse: 1.8116 - learning_rate: 1.2500e-06\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "148/148 - 5s - 35ms/step - loss: 0.0224 - mae: 0.1895 - mape: 9403.2334 - mse: 0.0450 - rmse: 0.2117 - val_loss: 1.1741 - val_mae: 1.6750 - val_mape: 190.8282 - val_mse: 3.2137 - val_rmse: 1.7894 - learning_rate: 1.2500e-06\n",
      "Epoch 24/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0223 - mae: 0.1885 - mape: 7356.7197 - mse: 0.0447 - rmse: 0.2111 - val_loss: 1.1633 - val_mae: 1.6639 - val_mape: 189.5045 - val_mse: 3.1774 - val_rmse: 1.7793 - learning_rate: 1.0000e-06\n",
      "Epoch 25/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0222 - mae: 0.1877 - mape: 5892.2559 - mse: 0.0445 - rmse: 0.2106 - val_loss: 1.1495 - val_mae: 1.6495 - val_mape: 187.7908 - val_mse: 3.1310 - val_rmse: 1.7662 - learning_rate: 1.0000e-06\n",
      "Epoch 26/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0221 - mae: 0.1869 - mape: 4605.6143 - mse: 0.0443 - rmse: 0.2101 - val_loss: 1.1365 - val_mae: 1.6360 - val_mape: 186.1786 - val_mse: 3.0883 - val_rmse: 1.7541 - learning_rate: 1.0000e-06\n",
      "Epoch 27/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0220 - mae: 0.1862 - mape: 3412.2456 - mse: 0.0442 - rmse: 0.2097 - val_loss: 1.1243 - val_mae: 1.6231 - val_mape: 184.6385 - val_mse: 3.0484 - val_rmse: 1.7427 - learning_rate: 1.0000e-06\n",
      "Epoch 28/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0219 - mae: 0.1855 - mape: 2297.5181 - mse: 0.0440 - rmse: 0.2092 - val_loss: 1.1119 - val_mae: 1.6100 - val_mape: 183.0708 - val_mse: 3.0084 - val_rmse: 1.7312 - learning_rate: 1.0000e-06\n",
      "Epoch 29/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0218 - mae: 0.1849 - mape: 1258.9297 - mse: 0.0438 - rmse: 0.2088 - val_loss: 1.1013 - val_mae: 1.5988 - val_mape: 181.7155 - val_mse: 2.9750 - val_rmse: 1.7215 - learning_rate: 1.0000e-06\n",
      "Epoch 30/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0217 - mae: 0.1842 - mape: 301.3278 - mse: 0.0436 - rmse: 0.2084 - val_loss: 1.0918 - val_mae: 1.5885 - val_mape: 180.4787 - val_mse: 2.9454 - val_rmse: 1.7129 - learning_rate: 1.0000e-06\n",
      "Epoch 31/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0216 - mae: 0.1835 - mape: 961.1188 - mse: 0.0434 - rmse: 0.2079 - val_loss: 1.0844 - val_mae: 1.5805 - val_mape: 179.4995 - val_mse: 2.9231 - val_rmse: 1.7064 - learning_rate: 1.0000e-06\n",
      "Epoch 32/50\n",
      "148/148 - 5s - 34ms/step - loss: 0.0215 - mae: 0.1829 - mape: 1975.4973 - mse: 0.0432 - rmse: 0.2075 - val_loss: 1.0772 - val_mae: 1.5727 - val_mape: 178.5469 - val_mse: 2.9021 - val_rmse: 1.7002 - learning_rate: 1.0000e-06\n",
      "Epoch 33/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0214 - mae: 0.1823 - mape: 2913.0493 - mse: 0.0431 - rmse: 0.2071 - val_loss: 1.0708 - val_mae: 1.5657 - val_mape: 177.6785 - val_mse: 2.8839 - val_rmse: 1.6948 - learning_rate: 1.0000e-06\n",
      "Epoch 34/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0214 - mae: 0.1817 - mape: 3779.8113 - mse: 0.0429 - rmse: 0.2067 - val_loss: 1.0657 - val_mae: 1.5598 - val_mape: 176.9543 - val_mse: 2.8698 - val_rmse: 1.6907 - learning_rate: 1.0000e-06\n",
      "Epoch 35/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0213 - mae: 0.1811 - mape: 4570.7227 - mse: 0.0427 - rmse: 0.2063 - val_loss: 1.0610 - val_mae: 1.5546 - val_mape: 176.2910 - val_mse: 2.8578 - val_rmse: 1.6871 - learning_rate: 1.0000e-06\n",
      "Epoch 36/50\n",
      "148/148 - 5s - 36ms/step - loss: 0.0212 - mae: 0.1805 - mape: 5278.5708 - mse: 0.0426 - rmse: 0.2059 - val_loss: 1.0575 - val_mae: 1.5505 - val_mape: 175.7655 - val_mse: 2.8498 - val_rmse: 1.6847 - learning_rate: 1.0000e-06\n",
      "Epoch 37/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0211 - mae: 0.1799 - mape: 5905.9019 - mse: 0.0424 - rmse: 0.2054 - val_loss: 1.0556 - val_mae: 1.5480 - val_mape: 175.4364 - val_mse: 2.8473 - val_rmse: 1.6840 - learning_rate: 1.0000e-06\n",
      "Epoch 38/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0210 - mae: 0.1794 - mape: 6494.9526 - mse: 0.0422 - rmse: 0.2051 - val_loss: 1.0546 - val_mae: 1.5466 - val_mape: 175.2232 - val_mse: 2.8481 - val_rmse: 1.6842 - learning_rate: 1.0000e-06\n",
      "Epoch 39/50\n",
      "148/148 - 5s - 36ms/step - loss: 0.0209 - mae: 0.1788 - mape: 7079.7256 - mse: 0.0421 - rmse: 0.2047 - val_loss: 1.0543 - val_mae: 1.5459 - val_mape: 175.0896 - val_mse: 2.8514 - val_rmse: 1.6852 - learning_rate: 1.0000e-06\n",
      "Epoch 40/50\n",
      "148/148 - 5s - 36ms/step - loss: 0.0209 - mae: 0.1783 - mape: 7700.1909 - mse: 0.0419 - rmse: 0.2043 - val_loss: 1.0548 - val_mae: 1.5460 - val_mape: 175.0503 - val_mse: 2.8575 - val_rmse: 1.6869 - learning_rate: 1.0000e-06\n",
      "Epoch 41/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0208 - mae: 0.1778 - mape: 8278.6045 - mse: 0.0418 - rmse: 0.2039 - val_loss: 1.0551 - val_mae: 1.5459 - val_mape: 174.9927 - val_mse: 2.8633 - val_rmse: 1.6886 - learning_rate: 1.0000e-06\n",
      "Epoch 42/50\n",
      "148/148 - 5s - 36ms/step - loss: 0.0207 - mae: 0.1772 - mape: 8850.8525 - mse: 0.0416 - rmse: 0.2035 - val_loss: 1.0560 - val_mae: 1.5464 - val_mape: 174.9941 - val_mse: 2.8710 - val_rmse: 1.6909 - learning_rate: 1.0000e-06\n",
      "Epoch 43/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0206 - mae: 0.1767 - mape: 9426.2100 - mse: 0.0414 - rmse: 0.2031 - val_loss: 1.0575 - val_mae: 1.5475 - val_mape: 175.0735 - val_mse: 2.8811 - val_rmse: 1.6938 - learning_rate: 1.0000e-06\n",
      "Epoch 44/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0205 - mae: 0.1762 - mape: 10011.8047 - mse: 0.0413 - rmse: 0.2027 - val_loss: 1.0593 - val_mae: 1.5490 - val_mape: 175.1945 - val_mse: 2.8927 - val_rmse: 1.6972 - learning_rate: 1.0000e-06\n",
      "Epoch 45/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0205 - mae: 0.1756 - mape: 10598.1768 - mse: 0.0411 - rmse: 0.2023 - val_loss: 1.0618 - val_mae: 1.5512 - val_mape: 175.3936 - val_mse: 2.9066 - val_rmse: 1.7013 - learning_rate: 1.0000e-06\n",
      "Epoch 46/50\n",
      "148/148 - 5s - 35ms/step - loss: 0.0204 - mae: 0.1751 - mape: 11135.0400 - mse: 0.0409 - rmse: 0.2019 - val_loss: 1.0660 - val_mae: 1.5551 - val_mape: 175.8000 - val_mse: 2.9263 - val_rmse: 1.7070 - learning_rate: 1.0000e-06\n",
      "Epoch 47/50\n",
      "148/148 - 5s - 36ms/step - loss: 0.0203 - mae: 0.1746 - mape: 11599.7725 - mse: 0.0408 - rmse: 0.2015 - val_loss: 1.0713 - val_mae: 1.5604 - val_mape: 176.3607 - val_mse: 2.9503 - val_rmse: 1.7140 - learning_rate: 1.0000e-06\n",
      "Epoch 48/50\n",
      "148/148 - 5s - 36ms/step - loss: 0.0202 - mae: 0.1740 - mape: 11994.8301 - mse: 0.0406 - rmse: 0.2011 - val_loss: 1.0771 - val_mae: 1.5661 - val_mape: 176.9700 - val_mse: 2.9761 - val_rmse: 1.7214 - learning_rate: 1.0000e-06\n",
      "Epoch 49/50\n",
      "148/148 - 6s - 40ms/step - loss: 0.0201 - mae: 0.1735 - mape: 12360.7686 - mse: 0.0405 - rmse: 0.2007 - val_loss: 1.0839 - val_mae: 1.5729 - val_mape: 177.7189 - val_mse: 3.0058 - val_rmse: 1.7300 - learning_rate: 1.0000e-06\n",
      "Epoch 50/50\n",
      "148/148 - 6s - 40ms/step - loss: 0.0201 - mae: 0.1730 - mape: 12722.1875 - mse: 0.0403 - rmse: 0.2003 - val_loss: 1.0900 - val_mae: 1.5790 - val_mape: 178.3691 - val_mse: 3.0334 - val_rmse: 1.7379 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>▁▄▅▅▄█▇▆▆▆▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃</td></tr><tr><td>epoch/mae</td><td>▁▄▄▄▄█▇▇▇▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>epoch/mape</td><td>▄▂▄█▆▇▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂</td></tr><tr><td>epoch/mse</td><td>▁▄▅▅▄█▇▆▆▆▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃</td></tr><tr><td>epoch/rmse</td><td>▁▅▅▆▅█▇▇▆▆▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>epoch/val_loss</td><td>▁▂▂▃█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_mae</td><td>▁▂▂▃█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_mape</td><td>▁▂▂▃█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.0</td></tr><tr><td>epoch/loss</td><td>0.02005</td></tr><tr><td>epoch/mae</td><td>0.17304</td></tr><tr><td>epoch/mape</td><td>12722.1875</td></tr><tr><td>epoch/mse</td><td>0.04031</td></tr><tr><td>epoch/rmse</td><td>0.20027</td></tr><tr><td>epoch/val_loss</td><td>1.09002</td></tr><tr><td>epoch/val_mae</td><td>1.57899</td></tr><tr><td>epoch/val_mape</td><td>178.36909</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">retrain_best_hp-lstm_@batch32_0</strong> at: <a href='https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b32@0' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b32@0</a><br> View project at: <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_233925-2026120_232746_541172@lstm@b32@0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/notebooks/wandb/run-20260120_234346-8kwylqw1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danielteam/idrx-forecast/runs/8kwylqw1' target=\"_blank\">toasty-fire-7345</a></strong> to <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danielteam/idrx-forecast/runs/8kwylqw1' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/8kwylqw1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   37 of 37 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available preprocessed datasets:\n",
      "\t['train@preprocessed-ds_2025121_172934_626424_batch@8', 'scaler.pkl', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid@preprocessed-ds_2025121_172934_626424_batch@8', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@16', 'valid@preprocessed-ds_2025121_172934_626424_batch@16', 'train@preprocessed-ds_2025121_172934_626424_batch@32', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid@preprocessed-ds_2025121_172934_626424_batch@32', 'train@preprocessed-ds_2025121_172934_626424_batch@16', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@16']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">toasty-fire-7345</strong> at: <a href='https://wandb.ai/danielteam/idrx-forecast/runs/8kwylqw1' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/8kwylqw1</a><br> View project at: <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_234346-8kwylqw1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train@preprocessed-ds_2025121_172934_626424_batch@8', 'scaler.pkl', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid@preprocessed-ds_2025121_172934_626424_batch@8', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@8', 'valid_outliers@preprocessed-ds_2025121_172934_626424_batch@16', 'valid@preprocessed-ds_2025121_172934_626424_batch@16', 'train@preprocessed-ds_2025121_172934_626424_batch@32', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@32', 'valid@preprocessed-ds_2025121_172934_626424_batch@32', 'train@preprocessed-ds_2025121_172934_626424_batch@16', 'train_outliers@preprocessed-ds_2025121_172934_626424_batch@16']\n",
      "train index: 8\n",
      "valid index: 10\n",
      "Model path: /Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/notebooks/artifacts/model-lstm--tuned-5best:v12/model-lstm:best-tuned-rank1.keras\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/notebooks/wandb/run-20260120_234354-2026120_232746_541172@lstm@b32@1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b32@1' target=\"_blank\">retrain_best_hp-lstm_@batch32_1</a></strong> to <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b32@1' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b32@1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/.venv/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'nadam', because it has 25 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 - 7s - 48ms/step - loss: 0.0345 - mae: 0.1895 - mape: 15323.5947 - mse: 0.0700 - rmse: 0.2635 - val_loss: 0.1049 - val_mae: 0.4465 - val_mape: 51.7693 - val_mse: 0.2102 - val_rmse: 0.4580 - learning_rate: 5.0000e-05\n",
      "Epoch 2/50\n",
      "148/148 - 7s - 48ms/step - loss: 0.0321 - mae: 0.1843 - mape: 129713.3750 - mse: 0.0652 - rmse: 0.2543 - val_loss: 0.3638 - val_mae: 0.8242 - val_mape: 94.8603 - val_mse: 0.7369 - val_rmse: 0.8572 - learning_rate: 5.0000e-05\n",
      "Epoch 3/50\n",
      "148/148 - 7s - 49ms/step - loss: 0.0273 - mae: 0.1803 - mape: 108267.6250 - mse: 0.0549 - rmse: 0.2336 - val_loss: 2.1402 - val_mae: 2.6429 - val_mape: 306.0902 - val_mse: 7.3041 - val_rmse: 2.6998 - learning_rate: 5.0000e-05\n",
      "Epoch 4/50\n",
      "148/148 - 11s - 73ms/step - loss: 0.0234 - mae: 0.1696 - mape: 89581.8750 - mse: 0.0471 - rmse: 0.2162 - val_loss: 6.2481 - val_mae: 6.7545 - val_mape: 783.4720 - val_mse: 47.3964 - val_rmse: 6.8778 - learning_rate: 5.0000e-05\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "148/148 - 8s - 51ms/step - loss: 0.0189 - mae: 0.1535 - mape: 48463.1133 - mse: 0.0381 - rmse: 0.1944 - val_loss: 8.2142 - val_mae: 8.7232 - val_mape: 1010.2810 - val_mse: 79.4999 - val_rmse: 8.9069 - learning_rate: 5.0000e-05\n",
      "Epoch 6/50\n",
      "148/148 - 8s - 52ms/step - loss: 0.0239 - mae: 0.1840 - mape: 23466.7031 - mse: 0.0481 - rmse: 0.2188 - val_loss: 5.9698 - val_mae: 6.4779 - val_mape: 746.5838 - val_mse: 44.7909 - val_rmse: 6.6841 - learning_rate: 2.5000e-06\n",
      "Epoch 7/50\n",
      "148/148 - 8s - 51ms/step - loss: 0.0200 - mae: 0.1664 - mape: 2884.9885 - mse: 0.0404 - rmse: 0.2002 - val_loss: 5.2656 - val_mae: 5.7732 - val_mape: 664.4741 - val_mse: 35.8281 - val_rmse: 5.9777 - learning_rate: 2.5000e-06\n",
      "Epoch 8/50\n",
      "148/148 - 7s - 50ms/step - loss: 0.0182 - mae: 0.1573 - mape: 8121.9951 - mse: 0.0368 - rmse: 0.1909 - val_loss: 4.8003 - val_mae: 5.3075 - val_mape: 610.4229 - val_mse: 30.3965 - val_rmse: 5.5057 - learning_rate: 2.5000e-06\n",
      "Epoch 9/50\n",
      "148/148 - 7s - 50ms/step - loss: 0.0172 - mae: 0.1514 - mape: 15991.6875 - mse: 0.0347 - rmse: 0.1853 - val_loss: 4.5295 - val_mae: 5.0365 - val_mape: 578.9964 - val_mse: 27.4330 - val_rmse: 5.2304 - learning_rate: 2.5000e-06\n",
      "Epoch 10/50\n",
      "148/148 - 7s - 50ms/step - loss: 0.0165 - mae: 0.1473 - mape: 20907.5742 - mse: 0.0333 - rmse: 0.1816 - val_loss: 4.3117 - val_mae: 4.8184 - val_mape: 553.6766 - val_mse: 25.1706 - val_rmse: 5.0099 - learning_rate: 2.5000e-06\n",
      "Epoch 11/50\n",
      "148/148 - 8s - 51ms/step - loss: 0.0160 - mae: 0.1444 - mape: 23810.4434 - mse: 0.0323 - rmse: 0.1789 - val_loss: 4.1811 - val_mae: 4.6877 - val_mape: 538.4962 - val_mse: 23.8622 - val_rmse: 4.8779 - learning_rate: 2.5000e-06\n",
      "Epoch 12/50\n",
      "148/148 - 9s - 61ms/step - loss: 0.0156 - mae: 0.1421 - mape: 25938.7559 - mse: 0.0315 - rmse: 0.1768 - val_loss: 4.0484 - val_mae: 4.5549 - val_mape: 522.9968 - val_mse: 22.5873 - val_rmse: 4.7457 - learning_rate: 2.5000e-06\n",
      "Epoch 13/50\n",
      "148/148 - 8s - 52ms/step - loss: 0.0153 - mae: 0.1402 - mape: 27155.2246 - mse: 0.0309 - rmse: 0.1749 - val_loss: 3.9906 - val_mae: 4.4971 - val_mape: 516.2328 - val_mse: 22.0486 - val_rmse: 4.6887 - learning_rate: 2.5000e-06\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "148/148 - 8s - 52ms/step - loss: 0.0150 - mae: 0.1382 - mape: 28217.0781 - mse: 0.0303 - rmse: 0.1732 - val_loss: 3.9061 - val_mae: 4.4126 - val_mape: 506.2982 - val_mse: 21.2813 - val_rmse: 4.6063 - learning_rate: 2.5000e-06\n",
      "Epoch 15/50\n",
      "148/148 - 8s - 52ms/step - loss: 0.0147 - mae: 0.1363 - mape: 28558.9727 - mse: 0.0296 - rmse: 0.1712 - val_loss: 3.7658 - val_mae: 4.2722 - val_mape: 489.7824 - val_mse: 20.0442 - val_rmse: 4.4703 - learning_rate: 1.0000e-06\n",
      "Epoch 16/50\n",
      "148/148 - 7s - 51ms/step - loss: 0.0145 - mae: 0.1356 - mape: 28856.0742 - mse: 0.0294 - rmse: 0.1705 - val_loss: 3.7133 - val_mae: 4.2197 - val_mape: 483.6082 - val_mse: 19.5914 - val_rmse: 4.4195 - learning_rate: 1.0000e-06\n",
      "Epoch 17/50\n",
      "148/148 - 7s - 50ms/step - loss: 0.0144 - mae: 0.1349 - mape: 29128.3555 - mse: 0.0291 - rmse: 0.1698 - val_loss: 3.6919 - val_mae: 4.1983 - val_mape: 481.0767 - val_mse: 19.4119 - val_rmse: 4.3992 - learning_rate: 1.0000e-06\n",
      "Epoch 18/50\n",
      "148/148 - 7s - 50ms/step - loss: 0.0143 - mae: 0.1343 - mape: 29325.5000 - mse: 0.0289 - rmse: 0.1692 - val_loss: 3.6789 - val_mae: 4.1853 - val_mape: 479.5258 - val_mse: 19.3071 - val_rmse: 4.3872 - learning_rate: 1.0000e-06\n",
      "Epoch 19/50\n",
      "148/148 - 8s - 51ms/step - loss: 0.0142 - mae: 0.1337 - mape: 29386.7188 - mse: 0.0287 - rmse: 0.1686 - val_loss: 3.6652 - val_mae: 4.1716 - val_mape: 477.8952 - val_mse: 19.1958 - val_rmse: 4.3746 - learning_rate: 1.0000e-06\n",
      "Epoch 20/50\n",
      "148/148 - 8s - 55ms/step - loss: 0.0141 - mae: 0.1331 - mape: 29377.6191 - mse: 0.0285 - rmse: 0.1679 - val_loss: 3.6591 - val_mae: 4.1655 - val_mape: 477.1466 - val_mse: 19.1521 - val_rmse: 4.3696 - learning_rate: 1.0000e-06\n",
      "Epoch 21/50\n",
      "148/148 - 9s - 58ms/step - loss: 0.0140 - mae: 0.1325 - mape: 29422.0547 - mse: 0.0283 - rmse: 0.1673 - val_loss: 3.6540 - val_mae: 4.1604 - val_mape: 476.5123 - val_mse: 19.1177 - val_rmse: 4.3656 - learning_rate: 1.0000e-06\n",
      "Epoch 22/50\n",
      "148/148 - 7s - 50ms/step - loss: 0.0139 - mae: 0.1320 - mape: 29338.3555 - mse: 0.0281 - rmse: 0.1667 - val_loss: 3.6557 - val_mae: 4.1621 - val_mape: 476.6730 - val_mse: 19.1436 - val_rmse: 4.3686 - learning_rate: 1.0000e-06\n",
      "Epoch 23/50\n",
      "148/148 - 8s - 51ms/step - loss: 0.0138 - mae: 0.1315 - mape: 28913.5137 - mse: 0.0279 - rmse: 0.1662 - val_loss: 3.6509 - val_mae: 4.1573 - val_mape: 476.0698 - val_mse: 19.1123 - val_rmse: 4.3650 - learning_rate: 1.0000e-06\n",
      "Epoch 24/50\n",
      "148/148 - 7s - 50ms/step - loss: 0.0137 - mae: 0.1310 - mape: 28292.5957 - mse: 0.0277 - rmse: 0.1656 - val_loss: 3.6544 - val_mae: 4.1608 - val_mape: 476.4373 - val_mse: 19.1533 - val_rmse: 4.3697 - learning_rate: 1.0000e-06\n",
      "Epoch 25/50\n",
      "148/148 - 7s - 50ms/step - loss: 0.0136 - mae: 0.1305 - mape: 28185.3438 - mse: 0.0275 - rmse: 0.1650 - val_loss: 3.6533 - val_mae: 4.1598 - val_mape: 476.2769 - val_mse: 19.1555 - val_rmse: 4.3699 - learning_rate: 1.0000e-06\n",
      "Epoch 26/50\n",
      "148/148 - 7s - 49ms/step - loss: 0.0135 - mae: 0.1301 - mape: 28151.1973 - mse: 0.0274 - rmse: 0.1645 - val_loss: 3.6570 - val_mae: 4.1635 - val_mape: 476.6616 - val_mse: 19.1975 - val_rmse: 4.3747 - learning_rate: 1.0000e-06\n",
      "Epoch 27/50\n",
      "148/148 - 7s - 49ms/step - loss: 0.0135 - mae: 0.1297 - mape: 28116.1445 - mse: 0.0272 - rmse: 0.1640 - val_loss: 3.6618 - val_mae: 4.1683 - val_mape: 477.1911 - val_mse: 19.2508 - val_rmse: 4.3807 - learning_rate: 1.0000e-06\n",
      "Epoch 28/50\n",
      "148/148 - 7s - 50ms/step - loss: 0.0134 - mae: 0.1292 - mape: 28096.4688 - mse: 0.0270 - rmse: 0.1635 - val_loss: 3.6651 - val_mae: 4.1717 - val_mape: 477.5377 - val_mse: 19.2910 - val_rmse: 4.3853 - learning_rate: 1.0000e-06\n",
      "Epoch 29/50\n",
      "148/148 - 9s - 57ms/step - loss: 0.0133 - mae: 0.1288 - mape: 27969.3086 - mse: 0.0269 - rmse: 0.1630 - val_loss: 3.6682 - val_mae: 4.1748 - val_mape: 477.8524 - val_mse: 19.3291 - val_rmse: 4.3896 - learning_rate: 1.0000e-06\n",
      "Epoch 30/50\n",
      "148/148 - 8s - 52ms/step - loss: 0.0132 - mae: 0.1284 - mape: 27831.6484 - mse: 0.0267 - rmse: 0.1626 - val_loss: 3.6780 - val_mae: 4.1846 - val_mape: 478.9523 - val_mse: 19.4269 - val_rmse: 4.4007 - learning_rate: 1.0000e-06\n",
      "Epoch 31/50\n",
      "148/148 - 7s - 50ms/step - loss: 0.0131 - mae: 0.1280 - mape: 27685.6836 - mse: 0.0266 - rmse: 0.1621 - val_loss: 3.6797 - val_mae: 4.1863 - val_mape: 479.1143 - val_mse: 19.4541 - val_rmse: 4.4038 - learning_rate: 1.0000e-06\n",
      "Epoch 32/50\n",
      "148/148 - 7s - 49ms/step - loss: 0.0131 - mae: 0.1276 - mape: 27480.9395 - mse: 0.0264 - rmse: 0.1617 - val_loss: 3.6917 - val_mae: 4.1983 - val_mape: 480.4662 - val_mse: 19.5705 - val_rmse: 4.4169 - learning_rate: 1.0000e-06\n",
      "Epoch 33/50\n",
      "148/148 - 7s - 50ms/step - loss: 0.0130 - mae: 0.1272 - mape: 27481.6934 - mse: 0.0263 - rmse: 0.1612 - val_loss: 3.6943 - val_mae: 4.2010 - val_mape: 480.7332 - val_mse: 19.6061 - val_rmse: 4.4209 - learning_rate: 1.0000e-06\n",
      "Epoch 34/50\n",
      "148/148 - 7s - 50ms/step - loss: 0.0129 - mae: 0.1268 - mape: 27873.4590 - mse: 0.0261 - rmse: 0.1608 - val_loss: 3.7029 - val_mae: 4.2096 - val_mape: 481.6958 - val_mse: 19.6941 - val_rmse: 4.4308 - learning_rate: 1.0000e-06\n",
      "Epoch 35/50\n",
      "148/148 - 7s - 50ms/step - loss: 0.0129 - mae: 0.1264 - mape: 27970.5234 - mse: 0.0260 - rmse: 0.1604 - val_loss: 3.7031 - val_mae: 4.2098 - val_mape: 481.6685 - val_mse: 19.7079 - val_rmse: 4.4324 - learning_rate: 1.0000e-06\n",
      "Epoch 36/50\n",
      "148/148 - 8s - 51ms/step - loss: 0.0128 - mae: 0.1261 - mape: 27520.5957 - mse: 0.0259 - rmse: 0.1600 - val_loss: 3.7084 - val_mae: 4.2151 - val_mape: 482.2509 - val_mse: 19.7672 - val_rmse: 4.4390 - learning_rate: 1.0000e-06\n",
      "Epoch 37/50\n",
      "148/148 - 9s - 60ms/step - loss: 0.0127 - mae: 0.1258 - mape: 27067.0234 - mse: 0.0258 - rmse: 0.1596 - val_loss: 3.7152 - val_mae: 4.2220 - val_mape: 483.0026 - val_mse: 19.8393 - val_rmse: 4.4471 - learning_rate: 1.0000e-06\n",
      "Epoch 38/50\n",
      "148/148 - 8s - 52ms/step - loss: 0.0127 - mae: 0.1254 - mape: 26720.7930 - mse: 0.0256 - rmse: 0.1592 - val_loss: 3.7158 - val_mae: 4.2225 - val_mape: 483.0258 - val_mse: 19.8556 - val_rmse: 4.4489 - learning_rate: 1.0000e-06\n",
      "Epoch 39/50\n",
      "148/148 - 8s - 52ms/step - loss: 0.0126 - mae: 0.1251 - mape: 26319.9668 - mse: 0.0255 - rmse: 0.1588 - val_loss: 3.7182 - val_mae: 4.2249 - val_mape: 483.2699 - val_mse: 19.8881 - val_rmse: 4.4526 - learning_rate: 1.0000e-06\n",
      "Epoch 40/50\n",
      "148/148 - 8s - 52ms/step - loss: 0.0126 - mae: 0.1247 - mape: 25763.0332 - mse: 0.0254 - rmse: 0.1585 - val_loss: 3.7210 - val_mae: 4.2277 - val_mape: 483.5502 - val_mse: 19.9243 - val_rmse: 4.4566 - learning_rate: 1.0000e-06\n",
      "Epoch 41/50\n",
      "148/148 - 8s - 53ms/step - loss: 0.0125 - mae: 0.1244 - mape: 25318.4160 - mse: 0.0253 - rmse: 0.1581 - val_loss: 3.7224 - val_mae: 4.2291 - val_mape: 483.6690 - val_mse: 19.9490 - val_rmse: 4.4594 - learning_rate: 1.0000e-06\n",
      "Epoch 42/50\n",
      "148/148 - 8s - 51ms/step - loss: 0.0124 - mae: 0.1240 - mape: 24737.4141 - mse: 0.0251 - rmse: 0.1577 - val_loss: 3.7278 - val_mae: 4.2346 - val_mape: 484.2660 - val_mse: 20.0096 - val_rmse: 4.4661 - learning_rate: 1.0000e-06\n",
      "Epoch 43/50\n",
      "148/148 - 8s - 52ms/step - loss: 0.0124 - mae: 0.1237 - mape: 24320.9668 - mse: 0.0250 - rmse: 0.1573 - val_loss: 3.7343 - val_mae: 4.2411 - val_mape: 484.9797 - val_mse: 20.0793 - val_rmse: 4.4739 - learning_rate: 1.0000e-06\n",
      "Epoch 44/50\n",
      "148/148 - 8s - 52ms/step - loss: 0.0123 - mae: 0.1234 - mape: 23728.7773 - mse: 0.0249 - rmse: 0.1569 - val_loss: 3.7427 - val_mae: 4.2495 - val_mape: 485.9168 - val_mse: 20.1659 - val_rmse: 4.4835 - learning_rate: 1.0000e-06\n",
      "Epoch 45/50\n",
      "148/148 - 8s - 53ms/step - loss: 0.0123 - mae: 0.1231 - mape: 23294.2949 - mse: 0.0248 - rmse: 0.1566 - val_loss: 3.7501 - val_mae: 4.2570 - val_mape: 486.7479 - val_mse: 20.2431 - val_rmse: 4.4921 - learning_rate: 1.0000e-06\n",
      "Epoch 46/50\n",
      "148/148 - 8s - 54ms/step - loss: 0.0122 - mae: 0.1227 - mape: 22785.8184 - mse: 0.0247 - rmse: 0.1562 - val_loss: 3.7527 - val_mae: 4.2595 - val_mape: 487.0019 - val_mse: 20.2766 - val_rmse: 4.4958 - learning_rate: 1.0000e-06\n",
      "Epoch 47/50\n",
      "148/148 - 8s - 54ms/step - loss: 0.0121 - mae: 0.1224 - mape: 22400.6738 - mse: 0.0246 - rmse: 0.1558 - val_loss: 3.7593 - val_mae: 4.2661 - val_mape: 487.7389 - val_mse: 20.3460 - val_rmse: 4.5035 - learning_rate: 1.0000e-06\n",
      "Epoch 48/50\n",
      "148/148 - 7s - 50ms/step - loss: 0.0121 - mae: 0.1221 - mape: 22020.3789 - mse: 0.0244 - rmse: 0.1555 - val_loss: 3.7613 - val_mae: 4.2682 - val_mape: 487.9365 - val_mse: 20.3754 - val_rmse: 4.5068 - learning_rate: 1.0000e-06\n",
      "Epoch 49/50\n",
      "148/148 - 8s - 55ms/step - loss: 0.0120 - mae: 0.1218 - mape: 21667.8984 - mse: 0.0243 - rmse: 0.1551 - val_loss: 3.7664 - val_mae: 4.2733 - val_mape: 488.5033 - val_mse: 20.4301 - val_rmse: 4.5128 - learning_rate: 1.0000e-06\n",
      "Epoch 50/50\n",
      "148/148 - 11s - 75ms/step - loss: 0.0120 - mae: 0.1215 - mape: 21349.9785 - mse: 0.0242 - rmse: 0.1548 - val_loss: 3.7690 - val_mae: 4.2759 - val_mape: 488.7682 - val_mse: 20.4638 - val_rmse: 4.5165 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▅▃▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mae</td><td>█▇▇▆▄▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/mape</td><td>▂█▇▆▄▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>epoch/mse</td><td>█▆▅▃▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/rmse</td><td>█▆▅▄▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>▁▁▃▆█▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>epoch/val_mae</td><td>▁▁▃▆█▆▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>epoch/val_mape</td><td>▁▁▃▆█▅▅▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.0</td></tr><tr><td>epoch/loss</td><td>0.01198</td></tr><tr><td>epoch/mae</td><td>0.12153</td></tr><tr><td>epoch/mape</td><td>21349.97852</td></tr><tr><td>epoch/mse</td><td>0.02423</td></tr><tr><td>epoch/rmse</td><td>0.1548</td></tr><tr><td>epoch/val_loss</td><td>3.769</td></tr><tr><td>epoch/val_mae</td><td>4.27588</td></tr><tr><td>epoch/val_mape</td><td>488.76822</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">retrain_best_hp-lstm_@batch32_1</strong> at: <a href='https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b32@1' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/2026120_232746_541172@lstm@b32@1</a><br> View project at: <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_234354-2026120_232746_541172@lstm@b32@1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/notebooks/wandb/run-20260120_235026-j0x1tt4r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danielteam/idrx-forecast/runs/j0x1tt4r' target=\"_blank\">visionary-valley-7347</a></strong> to <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danielteam/idrx-forecast/runs/j0x1tt4r' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/j0x1tt4r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/heykalsayid/Desktop/myown/machine_learning/usd-idr-forecasting/models/retrain/2026120_232746_541172-lstm)... Done. 0.1s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">visionary-valley-7347</strong> at: <a href='https://wandb.ai/danielteam/idrx-forecast/runs/j0x1tt4r' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast/runs/j0x1tt4r</a><br> View project at: <a href='https://wandb.ai/danielteam/idrx-forecast' target=\"_blank\">https://wandb.ai/danielteam/idrx-forecast</a><br>Synced 4 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260120_235026-j0x1tt4r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_retrainer.start(callbacks=[lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88a2a8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'16_0': <keras.src.callbacks.history.History at 0x123c54bd0>,\n",
       " '16_1': <keras.src.callbacks.history.History at 0x1242cbe50>,\n",
       " '32_0': <keras.src.callbacks.history.History at 0x124952490>,\n",
       " '32_1': <keras.src.callbacks.history.History at 0x124fc2bd0>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_histories = lstm_retrainer.get_model_histories\n",
    "lstm_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81b97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b2083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usd-idr-forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
